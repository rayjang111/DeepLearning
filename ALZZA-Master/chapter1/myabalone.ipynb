{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  파이썬 모듈 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import csv\n",
    "import time \n",
    "np.random.seed(1234)\n",
    "def randomize(): \n",
    "    np.random.seed(time.time()) ###만약 랜덤시드를 설정해주고싶으면 현재시간으로"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 하이퍼 파라미터값들 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "RND_MEAN = 0###정규분포평균\n",
    "RND_STD = 0.0030 ###정규분포 분산\n",
    "\n",
    "LEARNING_RATE = 0.001 ### 학습률"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 실험용 메인 함수 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def abalone_exec(epoch_count=10, mb_size=10, report=1):\n",
    "    load_abalone_dataset() ####e데이터를 불러올 함수 \n",
    "    init_model() ####파라미터 초기화 함수\n",
    "    train_and_test(epoch_count, mb_size, report) ###훈련하고 test할 함수"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 데이터 적재함수 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_abalone_dataset():\n",
    "    with open('../../data/chap01/abalone.csv') as csvfile: ###csv파일을 열어두고\n",
    "        csvreader = csv.reader(csvfile) ##메모리로 읽어온다\n",
    "        next(csvreader, None) ### 첫번째줄 header이므로 넘어감 \n",
    "        rows = [] ###데이터를 담을 listt생성\n",
    "        for row in csvreader:\n",
    "            rows.append(row) ### 데이터가 담긴 row list 생성\n",
    "            \n",
    "    global data, input_cnt, output_cnt ###전역변수선언\n",
    "    input_cnt, output_cnt = 10, 1 ###데이터 크기에 따라 달라짐\n",
    "    data = np.zeros([len(rows), input_cnt+output_cnt]) ### 크기에 맞게 data를 생성\n",
    "\n",
    "    for n, row in enumerate(rows): ####성별 one hot encoding 후 나머지데이터 입력\n",
    "        if row[0] == 'I': data[n, 0] = 1\n",
    "        if row[0] == 'M': data[n, 1] = 1\n",
    "        if row[0] == 'F': data[n, 2] = 1\n",
    "        data[n, 3:] = row[1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 파라미터 초기화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_model():\n",
    "    global weight, bias, input_cnt, output_cnt\n",
    "    weight = np.random.normal(RND_MEAN, RND_STD,[input_cnt, output_cnt])\n",
    "    bias = np.zeros([output_cnt]) ###편향은 0으로 초기화시켜준다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 학습 및 평가 데이터 획득 함수 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_test(epoch_count,mb_size,report):\n",
    "    step_count=arrange_data(mb_size) ###데이터를 minibatch size로 나누고 학습용데이터와 train 데이터를 나눈다.\n",
    "    test_x, test_y= get_test_data() ###test용 데이터 분리\n",
    "    \n",
    "    for epoch in range(epoch_count): ##### epoch_count 만큼 train을 시킨다\n",
    "        losses,accs=[],[]\n",
    "        for n in range(step_count): ####minibatch 사이즈에 따라 정해진 step_count\n",
    "            train_x,train_y=get_train_data(mb_size,n) ##train 데이터를 나누고\n",
    "            loss,acc=run_train(train_x,train_y) ###훈련을 시킬때 나오는 loss acc값 저장\n",
    "            losses.append(loss)\n",
    "            accs.append(acc)\n",
    "        if report>0 and (epoch+1) %report== 0: ###어느 주기에 한번씩 report해줄것인지 지정\n",
    "            acc=run_test(test_x,test_y) #### 분기별 정확도 출력\n",
    "            print('Epoch {}: loss={:5.3f}, accuracy={:5.3f}/{:5.3f}'.format(epoch+1,np.mean(losses),np.mean(accs),acc))\n",
    "    final_acc=run_test(test_x,test_y) ###\n",
    "    print('\\nFinal Test: final accuracy= {:5.3f}'.format(final_acc)) #### 최종 정확도 출력\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 데이터 전처리함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def arrange_data(mb_size): ###데이터 정렬함수 \n",
    "    global data,shuffle_map,test_begin_idx ###전역변수 선언 데이터,정렬된 데이터, \n",
    "    shuffle_map=np.arange(data.shape[0])####일단 데이터개수만큼의 numpy array를 만들어주고\n",
    "    np.random.shuffle(shuffle_map) ### 랜덤배열을 해준다\n",
    "    step_count=int(data.shape[0]*0.8)//mb_size ###step_count를 통해 한 iteration당 몇번씩 할지 설정\n",
    "    test_begin_idx=step_count*mb_size ###테스트를 시작할 index를 미리 지정해준다\n",
    "    return step_count \n",
    "def get_test_data():\n",
    "    global data,shuffle_map, test_begin_idx,output_cnt \n",
    "    test_data=data[shuffle_map[test_begin_idx:]] ###data에서 shufflmap의 인덱스를 사용해서 test data추출\n",
    "    return test_data[:,:-output_cnt],test_data[:,-output_cnt:]####test set의 x,y 반환 \n",
    "def get_train_data(mb_size,nth):\n",
    "    global data,shuffle_map,test_begin_idx, output_cnr\n",
    "    if nth==0: ###매 에포크마다 한번 셔플 해주도록 한다. \n",
    "        np.random.shuffle(shuffle_map[:test_begin_idx])\n",
    "    train_data=data[shuffle_map[mb_size*nth:mb_size*(nth+1)]]\n",
    "    return train_data[:,:-output_cnt],train_data[:,-output_cnt:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 훈련용 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_train(x,y): ###훈련용함수\n",
    "    output, aux_nn= forward_neuralnet(x) ###신경망 연산에 해당하는 함수 \n",
    "    loss,aux_pp= forward_postproc(output,y) ####연산후처리에 관한 함수\n",
    "    accuracy=eval_accuracy(output,y)### 정확도 계산\n",
    "\n",
    "    G_loss=1.0 ### dL/dL값\n",
    "    G_output=backprop_postproc(G_loss,aux_pp) ##후처리에 대한 backpropa\n",
    "    backprop_neuralnet(G_output,aux_nn) ### 신경망 연산에 대한 backpropa\n",
    "    \n",
    "    return loss, accuracy\n",
    "def run_test(x,y):### 테스트용 함수 backpropa계산이 필요없다\n",
    "    output,_= forward_neuralnet(x)\n",
    "    accuracy=eval_accuracy(output,y)\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 순전파 역전파 함수 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_neuralnet(x):\n",
    "    global weight,bias ###전역변수 weight,bias 호출\n",
    "    output= np.matmul(x,weight)+bias ###출력 \n",
    "    return output,x \n",
    "def backprop_neuralnet(G_output,x): \n",
    "    global weight,bias\n",
    "    g_output_w=x.transpose() ### Wx 에서 x로 미분했을때 값\n",
    "    G_w=np.matmul(g_output_w,G_output)###w에 전해지는 backpropa\n",
    "    G_b=np.sum(G_output,axis=0)\n",
    "    weight-=LEARNING_RATE*G_w ###weight update\n",
    "    bias-=LEARNING_RATE*G_b ##bias update\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_postproc(output,y):\n",
    "    diff=output-y\n",
    "    square=np.square(diff)\n",
    "    loss=np.mean(square)\n",
    "    return loss,diff\n",
    "def backprop_postproc(G_loss,diff):\n",
    "    shape=diff.shape\n",
    "    g_loss_square=np.ones(shape)/np.prod(shape)\n",
    "    g_square_diff=2*diff\n",
    "    g_diff_output=1\n",
    "    G_square=g_loss_square*G_loss\n",
    "    G_diff=g_square_diff*G_square\n",
    "    G_output=g_diff_output*G_diff\n",
    "    return G_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_accuracy(output,y):\n",
    "    mdiff=np.mean((np.abs(output-y)/y))\n",
    "    return 1-mdiff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
